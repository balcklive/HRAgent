# HR Agent æµå¼è¾“å‡ºå®ç°æ–¹æ¡ˆ

## æ–‡æ¡£ä¿¡æ¯
- **åˆ›å»ºæ—¶é—´**: 2025-07-15
- **ç‰ˆæœ¬**: v1.0
- **ä½œè€…**: Claude Code Assistant
- **çŠ¶æ€**: æ–¹æ¡ˆè¯„ä¼°å®Œæˆï¼Œå¾…å®æ–½

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

### éœ€æ±‚æè¿°
å½“å‰HR Agentç³»ç»Ÿåœ¨å‰ç«¯äº¤äº’æ—¶ï¼Œæ™ºèƒ½ä½“åŠ©æ‰‹çš„è¾“å‡ºå¹¶ä¸æ˜¯æµå¼çš„ï¼Œæ˜¾å¾—éå¸¸ä¸æµç•…ã€‚ç”±äºåº•å±‚è°ƒç”¨çš„æ˜¯LLMå¤§æ¨¡å‹ï¼Œä»æŠ€æœ¯è§’åº¦æ”¯æŒæµå¼è¾“å‡ºï¼Œéœ€è¦å°†å‰ç«¯æ™ºèƒ½ä½“çš„è¾“å‡ºä¿®æ”¹ä¸ºæµå¼ä»¥æå‡ç”¨æˆ·ä½“éªŒã€‚

### ç›®æ ‡
- å®ç°æ™ºèƒ½ä½“å›å¤çš„æµå¼è¾“å‡º
- æå‡ç”¨æˆ·äº¤äº’ä½“éªŒçš„æµç•…æ€§
- é™ä½ç”¨æˆ·ç­‰å¾…æ—¶çš„ç„¦è™‘æ„Ÿ
- ä½¿äº§å“ä½“éªŒæ›´æ¥è¿‘ç°ä»£AIåº”ç”¨æ ‡å‡†

## ğŸ” å½“å‰æ¶æ„åˆ†æ

### æŠ€æœ¯æ ˆ
- **åç«¯æ¡†æ¶**: FastAPI (å¼‚æ­¥Webæ¡†æ¶)
- **LLMé›†æˆ**: LangChain + OpenAI GPT-4o-mini
- **å·¥ä½œæµå¼•æ“**: LangGraph
- **æ•°æ®æ¨¡å‹**: Pydantic
- **å‰ç«¯**: JavaScript + Bootstrap
- **å¹¶å‘å¤„ç†**: Python asyncio

### å½“å‰é—®é¢˜
1. **LLMè°ƒç”¨å±‚é¢**: ä½¿ç”¨`llm.invoke()`åŒæ­¥è°ƒç”¨ï¼Œè¿”å›å®Œæ•´å“åº”
2. **åç«¯APIå±‚é¢**: ä½¿ç”¨JSONResponseè¿”å›å®Œæ•´å†…å®¹ï¼Œæ²¡æœ‰æµå¼æœºåˆ¶
3. **å‰ç«¯å¤„ç†å±‚é¢**: ä½¿ç”¨ä¼ ç»Ÿfetch APIç­‰å¾…å®Œæ•´å“åº”ï¼Œä¸€æ¬¡æ€§æ˜¾ç¤º

### å…³é”®ä»£ç ä½ç½®
```python
# æ–‡ä»¶: src/nodes/requirement_confirmation_node.py:81
response = self.llm.invoke(messages)
return response.content

# æ–‡ä»¶: web_interface/app.py:242-350
@app.post("/chat/message")
async def process_chat_message():
    result = requirement_node.process(requirement_state, message)
    return JSONResponse({"message": result["message"]})

# æ–‡ä»¶: web_interface/static/js/chat.js:89-94
const response = await fetch('/chat/message', {method: 'POST', body: formData});
const data = await response.json();
this.addBotMessage(data.message);
```

## ğŸ’¡ æŠ€æœ¯æ–¹æ¡ˆ

### æ–¹æ¡ˆé€‰æ‹©ï¼šServer-Sent Events (SSE)
**é€‰æ‹©ç†ç”±**ï¼š
- å®ç°ç›¸å¯¹ç®€å•ï¼Œæµè§ˆå™¨åŸç”Ÿæ”¯æŒ
- è‡ªåŠ¨é‡è¿æœºåˆ¶
- å•å‘æ•°æ®æµï¼Œé€‚åˆèŠå¤©åœºæ™¯
- ä¸ç°æœ‰æ¶æ„å…¼å®¹æ€§å¥½

### æ ¸å¿ƒå®ç°æ€è·¯
1. **åç«¯**: ä½¿ç”¨`llm.astream()`å®ç°æµå¼LLMè°ƒç”¨
2. **API**: ä½¿ç”¨FastAPIçš„`StreamingResponse`è¿”å›SSEæµ
3. **å‰ç«¯**: ä½¿ç”¨`EventSource`æ¥æ”¶æµå¼æ•°æ®å¹¶æ¸è¿›å¼æ›´æ–°UI

## ğŸ› ï¸ è¯¦ç»†å®ç°æ–¹æ¡ˆ

### 1. åç«¯ä¿®æ”¹

#### 1.1 LLMå±‚ä¿®æ”¹
```python
# æ–‡ä»¶: src/nodes/requirement_confirmation_node.py
class RequirementConfirmationNode:
    def __init__(self, model_name: str = "gpt-4o-mini", temperature: float = 0.3):
        self.llm = ChatOpenAI(
            model=model_name, 
            temperature=temperature,
            streaming=True  # å¯ç”¨æµå¼æ”¯æŒ
        )
    
    async def process_stream(self, state: RequirementConfirmationState, user_input: Optional[str] = None):
        """æµå¼å¤„ç†éœ€æ±‚ç¡®è®¤"""
        # æ„å»ºæ¶ˆæ¯ï¼ˆå¤ç”¨ç°æœ‰é€»è¾‘ï¼‰
        messages = self._build_messages(state, user_input)
        
        full_response = ""
        async for chunk in self.llm.astream(messages):
            content = chunk.content
            full_response += content
            
            yield {
                "type": "content",
                "content": content,
                "is_complete": False
            }
        
        # æµå¼å®Œæˆåï¼Œè¿›è¡ŒçŠ¶æ€æ›´æ–°å’Œå®Œæˆåˆ¤æ–­
        completion_status = self._parse_completion_status(full_response)
        
        # æ›´æ–°çŠ¶æ€
        state.conversation_history.append(
            InteractionMessage(role="assistant", content=full_response)
        )
        
        if completion_status.get("status") == "complete":
            # æ›´æ–°å®ŒæˆçŠ¶æ€
            state.position = completion_status["position"]
            state.must_have = completion_status["must_have"]
            state.nice_to_have = completion_status["nice_to_have"]
            state.deal_breaker = completion_status["deal_breaker"]
            state.is_complete = True
            
            yield {
                "type": "complete",
                "content": "",
                "is_complete": True,
                "job_requirement": state.to_job_requirement().dict()
            }
        else:
            yield {
                "type": "continue",
                "content": "",
                "is_complete": False
            }
```

#### 1.2 FastAPIæ¥å£ä¿®æ”¹
```python
# æ–‡ä»¶: web_interface/app.py
import json
from fastapi.responses import StreamingResponse

@app.post("/chat/message/stream")
async def process_chat_message_stream(
    session_id: str = Form(...),
    message: str = Form(...),
    step: str = Form(...)
):
    """æµå¼å¤„ç†èŠå¤©æ¶ˆæ¯"""
    try:
        if session_id not in chat_sessions:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        session = chat_sessions[session_id]
        
        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
        session["messages"].append({
            "role": "user",
            "content": message,
            "timestamp": datetime.now().isoformat()
        })
        
        async def generate():
            if step == "jd_input":
                # åˆ›å»ºéœ€æ±‚ç¡®è®¤çŠ¶æ€
                requirement_state = RequirementConfirmationState(jd_text=message)
                session["requirement_state"] = requirement_state.model_dump()
                
                # æµå¼å¤„ç†
                requirement_node = session["requirement_node"]
                async for chunk in requirement_node.process_stream(requirement_state):
                    # æ›´æ–°sessionçŠ¶æ€
                    session["requirement_state"] = requirement_state.model_dump()
                    
                    # å‘é€SSEæ•°æ®
                    yield f"data: {json.dumps(chunk)}\n\n"
                    
            elif step == "requirement_confirmation":
                # ç»§ç»­éœ€æ±‚ç¡®è®¤å¯¹è¯
                requirement_state_dict = session["requirement_state"]
                requirement_state = RequirementConfirmationState(**requirement_state_dict)
                requirement_node = session["requirement_node"]
                
                async for chunk in requirement_node.process_stream(requirement_state, message):
                    # æ›´æ–°sessionçŠ¶æ€
                    session["requirement_state"] = requirement_state.model_dump()
                    
                    # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                    if chunk.get("is_complete", False):
                        session["job_requirement"] = chunk["job_requirement"]
                        chunk["step"] = "file_upload"
                        chunk["need_files"] = True
                    else:
                        chunk["step"] = "requirement_confirmation"
                    
                    yield f"data: {json.dumps(chunk)}\n\n"
        
        return StreamingResponse(
            generate(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Headers": "Cache-Control"
            }
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ä¿ç•™åŸæœ‰æ¥å£ä½œä¸ºå¤‡ç”¨
@app.post("/chat/message")
async def process_chat_message_fallback(
    session_id: str = Form(...),
    message: str = Form(...),
    step: str = Form(...)
):
    """éæµå¼å¤„ç†èŠå¤©æ¶ˆæ¯ï¼ˆå¤‡ç”¨ï¼‰"""
    # ä¿æŒåŸæœ‰é€»è¾‘ä¸å˜
    # ...
```

### 2. å‰ç«¯ä¿®æ”¹

#### 2.1 æµå¼æ¶ˆæ¯å¤„ç†
```javascript
// æ–‡ä»¶: web_interface/static/js/chat.js
class ChatBot {
    constructor() {
        // ç°æœ‰åˆå§‹åŒ–ä»£ç ...
        this.currentEventSource = null;
        this.currentMessageBubble = null;
        this.streamingEnabled = true; // æµå¼å¼€å…³
    }
    
    async sendMessage() {
        const message = this.messageInput.value.trim();
        if (!message) return;
        
        // æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        this.addUserMessage(message);
        this.messageInput.value = '';
        this.autoResizeTextarea();
        
        // ç¦ç”¨è¾“å…¥
        this.disableInput();
        
        // æ˜¾ç¤ºè¾“å…¥çŠ¶æ€
        this.showTypingIndicator();
        
        if (this.streamingEnabled) {
            await this.sendMessageStream(message);
        } else {
            await this.sendMessageTraditional(message);
        }
    }
    
    async sendMessageStream(message) {
        try {
            // å‡†å¤‡SSEè¯·æ±‚
            const formData = new FormData();
            formData.append('session_id', this.sessionId);
            formData.append('message', message);
            formData.append('step', this.currentStep);
            
            // åˆ›å»ºç©ºçš„AIæ¶ˆæ¯æ°”æ³¡
            this.hideTypingIndicator();
            this.currentMessageBubble = this.createEmptyBotMessage();
            
            // å»ºç«‹SSEè¿æ¥
            const response = await fetch('/chat/message/stream', {
                method: 'POST',
                body: formData
            });
            
            if (!response.ok) {
                throw new Error('Stream request failed');
            }
            
            // å¤„ç†æµå¼å“åº”
            const reader = response.body.getReader();
            const decoder = new TextDecoder();
            let buffer = '';
            
            while (true) {
                const { done, value } = await reader.read();
                if (done) break;
                
                buffer += decoder.decode(value, { stream: true });
                
                // å¤„ç†å®Œæ•´çš„SSEæ¶ˆæ¯
                const lines = buffer.split('\n\n');
                buffer = lines.pop(); // ä¿ç•™ä¸å®Œæ•´çš„éƒ¨åˆ†
                
                for (const line of lines) {
                    if (line.startsWith('data: ')) {
                        const data = JSON.parse(line.slice(6));
                        await this.handleStreamChunk(data);
                    }
                }
            }
            
        } catch (error) {
            console.error('Stream failed:', error);
            this.hideTypingIndicator();
            this.addBotMessage('âŒ æŠ±æ­‰ï¼Œç½‘ç»œè¿æ¥å‡ºç°é—®é¢˜ï¼Œè¯·é‡è¯•ã€‚');
            this.enableInput();
        }
    }
    
    async handleStreamChunk(data) {
        if (data.type === 'content') {
            // è¿½åŠ å†…å®¹åˆ°å½“å‰æ¶ˆæ¯
            this.appendToCurrentMessage(data.content);
            
        } else if (data.type === 'complete') {
            // å®ŒæˆçŠ¶æ€å¤„ç†
            this.currentStep = data.step || 'file_upload';
            this.finalizeCurrentMessage();
            
            if (data.need_files) {
                this.showFileUploadPrompt();
            } else {
                this.enableInput();
            }
            
        } else if (data.type === 'continue') {
            // ç»§ç»­å¯¹è¯
            this.currentStep = data.step || 'requirement_confirmation';
            this.finalizeCurrentMessage();
            this.enableInput();
        }
    }
    
    createEmptyBotMessage() {
        const messageDiv = document.createElement('div');
        messageDiv.className = 'message bot-message';
        
        const avatar = document.createElement('div');
        avatar.className = 'avatar';
        avatar.innerHTML = '<i class="fas fa-robot"></i>';
        
        const messageContent = document.createElement('div');
        messageContent.className = 'message-content';
        
        const bubble = document.createElement('div');
        bubble.className = 'message-bubble';
        bubble.innerHTML = '<span class="cursor">â–</span>'; // å…‰æ ‡æ•ˆæœ
        
        const time = document.createElement('div');
        time.className = 'message-time';
        time.textContent = new Date().toLocaleTimeString();
        
        messageContent.appendChild(bubble);
        messageContent.appendChild(time);
        messageDiv.appendChild(avatar);
        messageDiv.appendChild(messageContent);
        
        this.chatMessages.appendChild(messageDiv);
        this.scrollToBottom();
        
        return messageDiv;
    }
    
    appendToCurrentMessage(content) {
        if (this.currentMessageBubble) {
            const bubble = this.currentMessageBubble.querySelector('.message-bubble');
            const cursor = bubble.querySelector('.cursor');
            
            if (cursor) {
                // åœ¨å…‰æ ‡å‰æ’å…¥å†…å®¹
                cursor.insertAdjacentHTML('beforebegin', content);
            } else {
                // å¦‚æœæ²¡æœ‰å…‰æ ‡ï¼Œç›´æ¥è¿½åŠ 
                bubble.innerHTML += content;
            }
            
            this.scrollToBottom();
        }
    }
    
    finalizeCurrentMessage() {
        if (this.currentMessageBubble) {
            const bubble = this.currentMessageBubble.querySelector('.message-bubble');
            const cursor = bubble.querySelector('.cursor');
            
            if (cursor) {
                cursor.remove(); // ç§»é™¤å…‰æ ‡
            }
            
            // å¤„ç†Markdownæ ¼å¼
            bubble.innerHTML = this.convertMarkdownToHtml(bubble.innerHTML);
            
            this.currentMessageBubble = null;
        }
    }
    
    // å¤‡ç”¨ä¼ ç»Ÿæ–¹å¼
    async sendMessageTraditional(message) {
        // ä¿æŒåŸæœ‰é€»è¾‘
        // ...
    }
}
```

#### 2.2 CSSæ ·å¼å¢å¼º
```css
/* æ–‡ä»¶: web_interface/static/css/style.css */

/* æµå¼æ¶ˆæ¯å…‰æ ‡æ•ˆæœ */
.message-bubble .cursor {
    animation: blink 1s infinite;
    color: var(--primary-color);
    font-weight: bold;
}

@keyframes blink {
    0%, 50% { opacity: 1; }
    51%, 100% { opacity: 0; }
}

/* æµå¼æ¶ˆæ¯æ¸ç°æ•ˆæœ */
.message-bubble.streaming {
    animation: fadeIn 0.3s ease-in-out;
}

@keyframes fadeIn {
    from { opacity: 0; transform: translateY(10px); }
    to { opacity: 1; transform: translateY(0); }
}

/* é”™è¯¯çŠ¶æ€æ ·å¼ */
.message-bubble.error {
    background-color: #f8d7da;
    color: #721c24;
    border: 1px solid #f5c6cb;
}

/* åŠ è½½çŠ¶æ€ä¼˜åŒ– */
.typing-indicator.streaming {
    display: none;
}
```

## ğŸ“Š å·¥ä½œé‡è¯„ä¼°

### å¼€å‘æ—¶é—´åˆ†è§£
| ä»»åŠ¡ | é¢„ä¼°æ—¶é—´ | éš¾åº¦ | ä¼˜å…ˆçº§ |
|------|---------|------|--------|
| åç«¯LLMæµå¼è°ƒç”¨ | 0.5å¤© | ç®€å• | é«˜ |
| FastAPIæµå¼æ¥å£ | 1å¤© | ä¸­ç­‰ | é«˜ |
| å‰ç«¯SSEå¤„ç† | 1å¤© | ä¸­ç­‰ | é«˜ |
| UIäº¤äº’ä¼˜åŒ– | 0.5å¤© | ç®€å• | ä¸­ |
| é”™è¯¯å¤„ç†å’Œå®¹é”™ | 0.5å¤© | ä¸­ç­‰ | é«˜ |
| æµ‹è¯•å’Œè°ƒä¼˜ | 0.5å¤© | ä¸­ç­‰ | ä¸­ |
| **æ€»è®¡** | **4å¤©** | **ä¸­ç­‰** | **é«˜** |

### æŠ€æœ¯é£é™©è¯„ä¼°
- **ä½é£é™©**: LangChainæµå¼APIç¨³å®šï¼ŒFastAPIæ”¯æŒå®Œå–„
- **ä¸­é£é™©**: å¹¶å‘å¤„ç†å’ŒçŠ¶æ€ç®¡ç†
- **é«˜é£é™©**: ç§»åŠ¨ç«¯å…¼å®¹æ€§é—®é¢˜

## ğŸ¯ å®æ–½è®¡åˆ’

### é˜¶æ®µ1ï¼šæ ¸å¿ƒåŠŸèƒ½å®ç° (2å¤©)
1. **Day 1**: åç«¯æµå¼è°ƒç”¨å®ç°
   - ä¿®æ”¹RequirementConfirmationNode
   - å®ç°process_streamæ–¹æ³•
   - æ·»åŠ æµå¼APIæ¥å£
   
2. **Day 2**: å‰ç«¯æµå¼å¤„ç†
   - å®ç°SSEæ¶ˆæ¯å¤„ç†
   - æ·»åŠ æµå¼UIæ›´æ–°é€»è¾‘
   - åŸºç¡€åŠŸèƒ½æµ‹è¯•

### é˜¶æ®µ2ï¼šåŠŸèƒ½å®Œå–„ (1å¤©)
3. **Day 3**: ä¼˜åŒ–å’Œå®¹é”™
   - é”™è¯¯å¤„ç†æœºåˆ¶
   - é‡è¿å’Œæ¢å¤é€»è¾‘
   - æ€§èƒ½ä¼˜åŒ–

### é˜¶æ®µ3ï¼šæµ‹è¯•å’Œéƒ¨ç½² (1å¤©)
4. **Day 4**: å…¨é¢æµ‹è¯•
   - åŠŸèƒ½æµ‹è¯•
   - å¹¶å‘æµ‹è¯•
   - ç§»åŠ¨ç«¯é€‚é…
   - æ–‡æ¡£å®Œå–„

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

### çŠ¶æ€ç®¡ç†
```python
# ä¼šè¯çŠ¶æ€ç»“æ„
chat_sessions[session_id] = {
    "session_id": session_id,
    "step": "requirement_confirmation",
    "messages": [],
    "requirement_state": RequirementConfirmationState,
    "requirement_node": RequirementConfirmationNode,
    "streaming_state": {
        "is_streaming": False,
        "current_response": "",
        "stream_id": None
    }
}
```

### é”™è¯¯å¤„ç†ç­–ç•¥
1. **ç½‘ç»œé”™è¯¯**: è‡ªåŠ¨é‡è¯•æœºåˆ¶ï¼Œæœ€å¤š3æ¬¡
2. **æœåŠ¡å™¨é”™è¯¯**: é™çº§åˆ°ä¼ ç»Ÿæ¨¡å¼
3. **è§£æé”™è¯¯**: æ˜¾ç¤ºé”™è¯¯æ¶ˆæ¯ï¼Œå…è®¸é‡æ–°å‘é€
4. **è¶…æ—¶å¤„ç†**: 30ç§’è¶…æ—¶ï¼Œè‡ªåŠ¨ä¸­æ–­æµå¼ä¼ è¾“

### æ€§èƒ½ä¼˜åŒ–
1. **ç¼“å†²åŒºç®¡ç†**: æ§åˆ¶å†…å­˜ä½¿ç”¨
2. **è¿æ¥æ± **: å¤ç”¨HTTPè¿æ¥
3. **å¹¶å‘é™åˆ¶**: æ¯ç”¨æˆ·æœ€å¤š1ä¸ªå¹¶å‘æµ
4. **æ¸…ç†æœºåˆ¶**: å®šæœŸæ¸…ç†è¿‡æœŸä¼šè¯

## ğŸ¨ ç”¨æˆ·ä½“éªŒè®¾è®¡

### è§†è§‰åé¦ˆ
- å…‰æ ‡é—ªçƒæ•ˆæœè¡¨ç¤ºæ­£åœ¨è¾“å…¥
- é€å­—æ˜¾ç¤ºæ–‡æœ¬ï¼Œæ¨¡æ‹Ÿæ‰“å­—æ•ˆæœ
- æµç•…çš„åŠ¨ç”»è¿‡æ¸¡

### äº¤äº’åé¦ˆ
- ç«‹å³æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
- 500mså†…å¼€å§‹æ˜¾ç¤ºAIå›å¤
- æµå¼è¿‡ç¨‹ä¸­ç¦ç”¨è¾“å…¥
- å®Œæˆåé‡æ–°å¯ç”¨äº¤äº’

### é”™è¯¯å¤„ç†
- å‹å¥½çš„é”™è¯¯æç¤º
- ä¸€é”®é‡è¯•åŠŸèƒ½
- é™çº§åˆ°ä¼ ç»Ÿæ¨¡å¼é€‰é¡¹

## ğŸ“ˆ é¢„æœŸæ”¶ç›Š

### ç”¨æˆ·ä½“éªŒæå‡
- æ„ŸçŸ¥å“åº”æ—¶é—´: 3-5ç§’ â†’ 0.5ç§’
- äº¤äº’æµç•…åº¦æå‡: 80%
- ç”¨æˆ·æ»¡æ„åº¦æå‡: é¢„æœŸ40%+

### æŠ€æœ¯æŒ‡æ ‡
- é¦–å­—ç¬¦å»¶è¿Ÿ: < 500ms
- æ‰“å­—é€Ÿåº¦: 50-100å­—ç¬¦/ç§’
- é”™è¯¯ç‡: < 1%
- å¹¶å‘æ”¯æŒ: 100+ ç”¨æˆ·

## ğŸš€ éƒ¨ç½²å’Œç›‘æ§

### éƒ¨ç½²é…ç½®
```python
# ç¯å¢ƒå˜é‡é…ç½®
STREAMING_ENABLED=true
STREAM_BUFFER_SIZE=1024
STREAM_TIMEOUT=30
MAX_CONCURRENT_STREAMS=100
```

### ç›‘æ§æŒ‡æ ‡
- æµå¼è¿æ¥æ•°
- å¹³å‡å“åº”æ—¶é—´
- é”™è¯¯ç‡ç»Ÿè®¡
- ç”¨æˆ·æ»¡æ„åº¦

## ğŸ“ åç»­ä¼˜åŒ–

### çŸ­æœŸä¼˜åŒ– (1-2å‘¨)
- ç§»åŠ¨ç«¯ä½“éªŒä¼˜åŒ–
- æ€§èƒ½ç›‘æ§å’Œè°ƒä¼˜
- ç”¨æˆ·åé¦ˆæ”¶é›†

### ä¸­æœŸæ‰©å±• (1-2æœˆ)
- æ‰©å±•åˆ°å…¶ä»–LLMèŠ‚ç‚¹
- æ”¯æŒå¤šæ¨¡æ€æµå¼è¾“å‡º
- è¯­éŸ³è¾“å…¥/è¾“å‡ºé›†æˆ

### é•¿æœŸè§„åˆ’ (3-6æœˆ)
- å®æ—¶åä½œåŠŸèƒ½
- æ™ºèƒ½é¢„æµ‹å’Œç¼“å­˜
- ä¸ªæ€§åŒ–äº¤äº’ä¼˜åŒ–

## ğŸ“‹ æ£€æŸ¥æ¸…å•

### å¼€å‘å‰æ£€æŸ¥
- [ ] ç¡®è®¤LangChainç‰ˆæœ¬æ”¯æŒastream
- [ ] éªŒè¯FastAPIç‰ˆæœ¬å…¼å®¹æ€§
- [ ] å‡†å¤‡æµ‹è¯•ç¯å¢ƒå’Œæ•°æ®
- [ ] å¤‡ä»½ç°æœ‰ä»£ç 

### å¼€å‘è¿‡ç¨‹æ£€æŸ¥
- [ ] åç«¯æµå¼APIå®ç°
- [ ] å‰ç«¯SSEå¤„ç†é€»è¾‘
- [ ] é”™è¯¯å¤„ç†æœºåˆ¶
- [ ] çŠ¶æ€ç®¡ç†ä¼˜åŒ–
- [ ] æ€§èƒ½æµ‹è¯•é€šè¿‡

### éƒ¨ç½²å‰æ£€æŸ¥
- [ ] åŠŸèƒ½æµ‹è¯•å®Œæˆ
- [ ] æ€§èƒ½æµ‹è¯•é€šè¿‡
- [ ] å…¼å®¹æ€§æµ‹è¯•é€šè¿‡
- [ ] æ–‡æ¡£æ›´æ–°å®Œæˆ
- [ ] ç›‘æ§é…ç½®å°±ç»ª

## ğŸ“š å‚è€ƒèµ„æ–™

### æŠ€æœ¯æ–‡æ¡£
- [LangChain Streaming](https://python.langchain.com/docs/expression_language/streaming)
- [FastAPI Streaming Response](https://fastapi.tiangolo.com/advanced/custom-response/#streamingresponse)
- [Server-Sent Events MDN](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events)

### å®ç°å‚è€ƒ
- [OpenAI Streaming API](https://platform.openai.com/docs/api-reference/chat/create#chat/create-stream)
- [ChatGPT Webå®ç°](https://github.com/Chanzhaoyu/chatgpt-web)
- [FastAPI SSE Example](https://github.com/tiangolo/fastapi/issues/2177)

---

**æ–‡æ¡£ç»´æŠ¤**: è¯·åœ¨å®æ–½è¿‡ç¨‹ä¸­åŠæ—¶æ›´æ–°æœ¬æ–‡æ¡£ï¼Œè®°å½•å®é™…é‡åˆ°çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆã€‚

**è”ç³»æ–¹å¼**: å¦‚æœ‰æŠ€æœ¯é—®é¢˜ï¼Œè¯·åœ¨é¡¹ç›®Issueä¸­æå‡ºã€‚