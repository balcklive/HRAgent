# Author: Peng Fei

import asyncio
from typing import List, Dict, Any, Optional, Callable
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from src.models import CandidateProfile, CandidateBasicInfo, Education, WorkExperience, Skill
from src.prompts import (
    RESUME_STRUCTURE_SYSTEM_PROMPT,
    RESUME_STRUCTURE_PROMPT_TEMPLATE
)
from src.utils.resume_parser import ResumeParser
import json
import re
import os
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor

class ResumeStructureNode:
    """ç®€å†ç»“æ„åŒ–èŠ‚ç‚¹ - å°†ç®€å†æ–‡æœ¬è½¬æ¢ä¸ºç»“æ„åŒ–æ•°æ®"""
    
    def __init__(self, 
                 model_name: str = "gpt-4o-mini", 
                 temperature: float = 0.3,
                 max_concurrent: int = 5,
                 save_structured_results: bool = True):
        self.llm = ChatOpenAI(model=model_name, temperature=temperature)
        self.max_concurrent = max_concurrent
        self.system_prompt = RESUME_STRUCTURE_SYSTEM_PROMPT
        self.resume_parser = ResumeParser()
        self.save_structured_results = save_structured_results
        
    async def process(self, resume_files: List[str]) -> Dict[str, Any]:
        """å¤„ç†å¤šä¸ªç®€å†æ–‡ä»¶"""
        try:
            # ç¬¬ä¸€æ­¥ï¼šè§£æç®€å†æ–‡ä»¶
            print(f"å¼€å§‹è§£æ {len(resume_files)} ä¸ªç®€å†æ–‡ä»¶...")
            parsed_resumes = await self.resume_parser.parse_multiple_resumes(resume_files)
            
            # è¿‡æ»¤æˆåŠŸè§£æçš„ç®€å†
            valid_resumes = [r for r in parsed_resumes if r["status"] == "success"]
            failed_resumes = [r for r in parsed_resumes if r["status"] == "error"]
            
            print(f"æˆåŠŸè§£æ: {len(valid_resumes)} ä¸ªï¼Œå¤±è´¥: {len(failed_resumes)} ä¸ª")
            
            # ç¬¬äºŒæ­¥ï¼šå¹¶å‘ç»“æ„åŒ–å¤„ç†
            print("å¼€å§‹ç»“æ„åŒ–å¤„ç†...")
            structured_results = await self._process_resumes_concurrently(valid_resumes)
            
            # ç¬¬ä¸‰æ­¥ï¼šä¿å­˜ç»“æ„åŒ–ç»“æœï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.save_structured_results:
                await self._save_structured_results_to_disk(structured_results)
            
            # ç¬¬å››æ­¥ï¼šåˆ›å»ºCandidateProfileå¯¹è±¡
            candidate_profiles = []
            for result in structured_results:
                if result["status"] == "success":
                    try:
                        profile = self._create_candidate_profile(result["structured_data"])
                        candidate_profiles.append(profile)
                    except Exception as e:
                        print(f"åˆ›å»ºå€™é€‰äººæ¡£æ¡ˆå¤±è´¥: {str(e)}")
                        continue
            
            return {
                "status": "success",
                "total_files": len(resume_files),
                "successful_parsed": len(valid_resumes),
                "successful_structured": len(candidate_profiles),
                "failed_files": failed_resumes,
                "candidate_profiles": candidate_profiles
            }
            
        except Exception as e:
            return {
                "status": "error",
                "error": str(e),
                "candidate_profiles": []
            }

    async def process_stream(self, resume_files: List[str], progress_callback: Optional[Callable] = None) -> List[Dict[str, Any]]:
        """å¤„ç†ç®€å†æ–‡ä»¶ï¼ˆå¸¦è¿›åº¦æµå¼è¾“å‡ºï¼‰"""
        if progress_callback:
            await progress_callback({
                "stage": "resume_processing",
                "message": "Start parsing resume files",
                "progress": 15,
                "total_items": len(resume_files),
                "completed_items": 0
            })
        
        # è§£æç®€å†æ–‡ä»¶
        parsed_resumes = await self._parse_resumes_with_progress(resume_files, progress_callback)
        
        if progress_callback:
            await progress_callback({
                "stage": "resume_processing",
                "message": "Start structuring resume content",
                "progress": 25,
                "total_items": len(parsed_resumes),
                "completed_items": 0
            })
        
        # ç»“æ„åŒ–ç®€å†
        structured_results = await self._process_resumes_concurrently_stream(parsed_resumes, progress_callback)
        
        if progress_callback:
            await progress_callback({
                "stage": "resume_processing",
                "message": "Saving structured results",
                "progress": 35,
                "total_items": len(structured_results),
                "completed_items": len(structured_results)
            })
        
        # ä¿å­˜ç»“æœ
        if self.save_structured_results:
            await self._save_structured_results_to_disk(structured_results)
        
        # åˆ›å»ºCandidateProfileå¯¹è±¡
        candidate_profiles = []
        for result in structured_results:
            if result["status"] == "success":
                try:
                    profile = self._create_candidate_profile(result["structured_data"])
                    candidate_profiles.append(profile)
                except Exception as e:
                    print(f"åˆ›å»ºå€™é€‰äººæ¡£æ¡ˆå¤±è´¥: {str(e)}")
                    continue
        
        if progress_callback:
            await progress_callback({
                "stage": "resume_processing",
                "message": "Resume processing completed",
                "progress": 40,
                "total_items": len(resume_files),
                "completed_items": len(resume_files)
            })
        
        return {
            "status": "success",
            "total_files": len(resume_files),
            "successful_parsed": len(parsed_resumes),
            "successful_structured": len(candidate_profiles),
            "failed_files": [r for r in parsed_resumes if r["status"] == "error"],
            "candidate_profiles": candidate_profiles
        }
    
    async def _process_resumes_concurrently(self, parsed_resumes: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å¹¶å‘å¤„ç†ç®€å†ç»“æ„åŒ–"""
        semaphore = asyncio.Semaphore(self.max_concurrent)
        
        async def process_single_resume(resume_data):
            async with semaphore:
                return await self._structure_single_resume(resume_data)
        
        tasks = [process_single_resume(resume) for resume in parsed_resumes]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸ç»“æœ
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                processed_results.append({
                    "status": "error",
                    "error": str(result),
                    "file_path": parsed_resumes[i]["file_path"]
                })
            else:
                processed_results.append(result)
        
        return processed_results
    
    async def _save_structured_results_to_disk(self, structured_results: List[Dict[str, Any]]) -> None:
        """ä¿å­˜ç»“æ„åŒ–ç»“æœåˆ°ç¡¬ç›˜"""
        try:
            # åˆ›å»ºä¿å­˜ç›®å½•
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            save_dir = f"structured_resumes_{timestamp}"
            os.makedirs(save_dir, exist_ok=True)
            
            print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜ç»“æ„åŒ–ç»“æœåˆ°ç›®å½•: {save_dir}")
            
            # ä¿å­˜æ¯ä¸ªå€™é€‰äººçš„ç»“æ„åŒ–ç»“æœ
            for i, result in enumerate(structured_results):
                if result["status"] == "success":
                    # ä»æ–‡ä»¶è·¯å¾„è·å–å€™é€‰äººåç§°
                    file_name = result.get("file_name", f"candidate_{i+1}")
                    candidate_name = os.path.splitext(file_name)[0]
                    
                    # å‡†å¤‡ä¿å­˜çš„æ•°æ®
                    save_data = {
                        "file_info": {
                            "original_file": result["file_path"],
                            "file_name": result["file_name"],
                            "processing_time": datetime.now().isoformat(),
                            "validation": result.get("validation", {})
                        },
                        "structured_data": result["structured_data"]
                    }
                    
                    # ä¿å­˜ä¸ºJSONæ–‡ä»¶
                    json_file = os.path.join(save_dir, f"{candidate_name}_structured.json")
                    with open(json_file, 'w', encoding='utf-8') as f:
                        json.dump(save_data, f, ensure_ascii=False, indent=2)
                    
                    # ä¿å­˜ä¸ºå¯è¯»çš„Markdownæ–‡ä»¶
                    md_file = os.path.join(save_dir, f"{candidate_name}_structured.md")
                    await self._save_as_markdown(save_data, md_file)
                    
                    # ä»ç»“æ„åŒ–æ•°æ®ä¸­æå–å€™é€‰äººå§“å
                    candidate_real_name = save_data["structured_data"].get("basic_info", {}).get("name", candidate_name)
                    print(f"âœ… å·²ä¿å­˜å€™é€‰äºº '{candidate_real_name}' çš„ç»“æ„åŒ–ç»“æœ")
                    
                elif result["status"] == "error":
                    # ä¿å­˜é”™è¯¯ä¿¡æ¯
                    error_file = os.path.join(save_dir, f"error_{i+1}.json")
                    with open(error_file, 'w', encoding='utf-8') as f:
                        json.dump(result, f, ensure_ascii=False, indent=2)
                    print(f"âŒ å·²ä¿å­˜é”™è¯¯ä¿¡æ¯: {result.get('file_path', 'unknown')}")
            
            # åˆ›å»ºæ±‡æ€»æ–‡ä»¶
            summary_file = os.path.join(save_dir, "summary.json")
            summary_data = {
                "processing_time": datetime.now().isoformat(),
                "total_files": len(structured_results),
                "successful_files": len([r for r in structured_results if r["status"] == "success"]),
                "failed_files": len([r for r in structured_results if r["status"] == "error"]),
                "results": [
                    {
                        "file_name": r.get("file_name", "unknown"),
                        "file_path": r.get("file_path", "unknown"),
                        "status": r["status"],
                        "candidate_name": r.get("structured_data", {}).get("basic_info", {}).get("name", "unknown") if r["status"] == "success" else None,
                        "error": r.get("error") if r["status"] == "error" else None
                    } for r in structured_results
                ]
            }
            
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“„ å·²åˆ›å»ºæ±‡æ€»æ–‡ä»¶: {summary_file}")
            print(f"ğŸ“ ç»“æ„åŒ–ç»“æœå·²ä¿å­˜åˆ°ç›®å½•: {save_dir}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æ„åŒ–ç»“æœå¤±è´¥: {str(e)}")
    
    async def _save_as_markdown(self, save_data: Dict[str, Any], md_file: str) -> None:
        """å°†ç»“æ„åŒ–æ•°æ®ä¿å­˜ä¸ºMarkdownæ ¼å¼"""
        try:
            structured_data = save_data["structured_data"]
            file_info = save_data["file_info"]
            
            md_content = []
            
            # æ ‡é¢˜
            candidate_name = structured_data.get("basic_info", {}).get("name", "æœªçŸ¥å€™é€‰äºº")
            md_content.append(f"# {candidate_name} - ç®€å†ç»“æ„åŒ–ç»“æœ\n")
            
            # æ–‡ä»¶ä¿¡æ¯
            md_content.append("## æ–‡ä»¶ä¿¡æ¯\n")
            md_content.append(f"- **åŸå§‹æ–‡ä»¶**: {file_info['original_file']}")
            md_content.append(f"- **å¤„ç†æ—¶é—´**: {file_info['processing_time']}")
            md_content.append(f"- **éªŒè¯çŠ¶æ€**: {'âœ… é€šè¿‡' if file_info.get('validation', {}).get('is_valid', False) else 'âš ï¸ å­˜åœ¨é—®é¢˜'}")
            if not file_info.get('validation', {}).get('is_valid', False):
                issues = file_info.get('validation', {}).get('issues', [])
                if issues:
                    md_content.append(f"- **é—®é¢˜**: {', '.join(issues)}")
            md_content.append("")
            
            # åŸºæœ¬ä¿¡æ¯
            basic_info = structured_data.get("basic_info", {})
            md_content.append("## åŸºæœ¬ä¿¡æ¯\n")
            md_content.append(f"- **å§“å**: {basic_info.get('name', 'æœªçŸ¥')}")
            md_content.append(f"- **é‚®ç®±**: {basic_info.get('email', 'æœªæä¾›')}")
            md_content.append(f"- **ç”µè¯**: {basic_info.get('phone', 'æœªæä¾›')}")
            md_content.append(f"- **æ‰€åœ¨åœ°**: {basic_info.get('location', 'æœªæä¾›')}")
            md_content.append(f"- **å·¥ä½œç»éªŒ**: {basic_info.get('experience_years', 0)} å¹´")
            md_content.append(f"- **å½“å‰èŒä½**: {basic_info.get('current_role', 'æœªæä¾›')}")
            md_content.append(f"- **å½“å‰å…¬å¸**: {basic_info.get('current_company', 'æœªæä¾›')}")
            md_content.append("")
            
            # æ•™è‚²èƒŒæ™¯
            education = structured_data.get("education", [])
            md_content.append("## æ•™è‚²èƒŒæ™¯\n")
            if education:
                for edu in education:
                    md_content.append(f"- **{edu.get('degree', 'æœªçŸ¥å­¦ä½')}** - {edu.get('major', 'æœªçŸ¥ä¸“ä¸š')}")
                    md_content.append(f"  - å­¦æ ¡: {edu.get('school', 'æœªçŸ¥')}")
                    md_content.append(f"  - æ¯•ä¸šå¹´ä»½: {edu.get('graduation_year', 'æœªçŸ¥')}")
                    if edu.get('gpa'):
                        md_content.append(f"  - GPA: {edu.get('gpa')}")
            else:
                md_content.append("- æ— æ•™è‚²èƒŒæ™¯ä¿¡æ¯")
            md_content.append("")
            
            # å·¥ä½œç»å†
            work_experience = structured_data.get("work_experience", [])
            md_content.append("## å·¥ä½œç»å†\n")
            if work_experience:
                for work in work_experience:
                    md_content.append(f"### {work.get('position', 'æœªçŸ¥èŒä½')} - {work.get('company', 'æœªçŸ¥å…¬å¸')}")
                    md_content.append(f"- **æ—¶é—´**: {work.get('start_date', 'æœªçŸ¥')} è‡³ {work.get('end_date', 'æœªçŸ¥')}")
                    if work.get('description'):
                        md_content.append(f"- **æè¿°**: {work.get('description')}")
                    achievements = work.get('achievements', [])
                    if achievements:
                        md_content.append("- **ä¸»è¦æˆå°±**:")
                        for achievement in achievements:
                            md_content.append(f"  - {achievement}")
                    md_content.append("")
            else:
                md_content.append("- æ— å·¥ä½œç»å†ä¿¡æ¯\n")
            
            # æŠ€èƒ½ä¿¡æ¯
            skills = structured_data.get("skills", [])
            md_content.append("## æŠ€èƒ½ä¿¡æ¯\n")
            if skills:
                for skill in skills:
                    skill_info = f"- **{skill.get('name', 'æœªçŸ¥æŠ€èƒ½')}"
                    if skill.get('level'):
                        skill_info += f"** ({skill.get('level')})"
                    else:
                        skill_info += "**"
                    if skill.get('years_experience'):
                        skill_info += f" - {skill.get('years_experience')} å¹´ç»éªŒ"
                    md_content.append(skill_info)
                    if skill.get('description'):
                        md_content.append(f"  - {skill.get('description')}")
            else:
                md_content.append("- æ— æŠ€èƒ½ä¿¡æ¯")
            md_content.append("")
            
            # å…¶ä»–ä¿¡æ¯
            certifications = structured_data.get("certifications", [])
            if certifications:
                md_content.append("## è®¤è¯è¯ä¹¦\n")
                for cert in certifications:
                    md_content.append(f"- {cert}")
                md_content.append("")
            
            languages = structured_data.get("languages", [])
            if languages:
                md_content.append("## è¯­è¨€èƒ½åŠ›\n")
                for lang in languages:
                    md_content.append(f"- {lang}")
                md_content.append("")
            
            projects = structured_data.get("projects", [])
            if projects:
                md_content.append("## é¡¹ç›®ç»éªŒ\n")
                for project in projects:
                    md_content.append(f"- {project}")
                md_content.append("")
            
            # é“¾æ¥ä¿¡æ¯
            links = []
            if structured_data.get("github_url"):
                links.append(f"- **GitHub**: {structured_data.get('github_url')}")
            if structured_data.get("linkedin_url"):
                links.append(f"- **LinkedIn**: {structured_data.get('linkedin_url')}")
            
            if links:
                md_content.append("## é“¾æ¥ä¿¡æ¯\n")
                md_content.extend(links)
                md_content.append("")
            
            # å†™å…¥æ–‡ä»¶
            with open(md_file, 'w', encoding='utf-8') as f:
                f.write('\n'.join(md_content))
                
        except Exception as e:
            print(f"âŒ ä¿å­˜Markdownæ–‡ä»¶å¤±è´¥: {str(e)}")
    
    async def _structure_single_resume(self, resume_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç»“æ„åŒ–å•ä¸ªç®€å†"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰contentå­—æ®µ
            if "content" not in resume_data:
                return {
                    "status": "error",
                    "error": "ç¼ºå°‘ç®€å†å†…å®¹",
                    "file_path": resume_data.get("file_path", "unknown")
                }
            
            content = resume_data["content"]
            file_name = resume_data.get("file_name", "unknown")
            
            # æ¸…ç†æ–‡æœ¬
            clean_content = self.resume_parser.clean_text(content)
            
            # éªŒè¯å†…å®¹è´¨é‡
            validation = self.resume_parser.validate_resume_content(clean_content)
            if not validation["is_valid"]:
                print(f"ç®€å†è´¨é‡è­¦å‘Š [{file_name}]: {validation['issues']}")
            
            # æ„å»ºæç¤º
            prompt = self._build_structure_prompt(clean_content, file_name)
            
            # è°ƒç”¨LLM
            messages = [
                SystemMessage(content=self.system_prompt),
                HumanMessage(content=prompt)
            ]
            
            response = self.llm.invoke(messages)
            
            # è§£æå“åº”
            structured_data = self._parse_structured_response(response.content)
            
            return {
                "status": "success",
                "file_path": resume_data["file_path"],
                "file_name": file_name,
                "structured_data": structured_data,
                "validation": validation
            }
            
        except Exception as e:
            return {
                "status": "error",
                "error": str(e),
                "file_path": resume_data["file_path"]
            }
    
    def _build_structure_prompt(self, content: str, file_name: str) -> str:
        """æ„å»ºç»“æ„åŒ–æç¤º"""
        return RESUME_STRUCTURE_PROMPT_TEMPLATE.format(
            file_name=file_name,
            content=content
        )
    
    def _parse_structured_response(self, response: str) -> Dict[str, Any]:
        """è§£æç»“æ„åŒ–å“åº”"""
        try:
            # å°è¯•æå–JSON
            json_match = re.search(r'```json\s*(.*?)\s*```', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                return json.loads(json_str)
            
            # å¦‚æœæ²¡æœ‰```json```æ ‡è®°ï¼Œå°è¯•ç›´æ¥è§£æ
            lines = response.split('\n')
            json_start = -1
            json_end = -1
            
            for i, line in enumerate(lines):
                if '{' in line and json_start == -1:
                    json_start = i
                if '}' in line and json_start != -1:
                    json_end = i
                    break
            
            if json_start != -1 and json_end != -1:
                json_str = '\n'.join(lines[json_start:json_end+1])
                return json.loads(json_str)
            
            # å¦‚æœéƒ½å¤±è´¥ï¼Œè¿”å›é»˜è®¤ç»“æ„
            return self._get_default_structure()
            
        except json.JSONDecodeError:
            return self._get_default_structure()
    
    def _get_default_structure(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤ç»“æ„åŒ–æ•°æ®"""
        return {
            "basic_info": {
                "name": "æœªçŸ¥",
                "email": None,
                "phone": None,
                "location": None,
                "experience_years": 0,
                "current_role": None,
                "current_company": None
            },
            "education": [],
            "work_experience": [],
            "skills": [],
            "certifications": [],
            "languages": [],
            "projects": [],
            "github_url": None,
            "linkedin_url": None
        }
    
    def _create_candidate_profile(self, structured_data: Dict[str, Any]) -> CandidateProfile:
        """åˆ›å»ºå€™é€‰äººæ¡£æ¡ˆå¯¹è±¡"""
        # åŸºæœ¬ä¿¡æ¯
        basic_info_data = structured_data.get("basic_info", {})
        basic_info = CandidateBasicInfo(
            name=basic_info_data.get("name", "æœªçŸ¥"),
            email=basic_info_data.get("email"),
            phone=basic_info_data.get("phone"),
            location=basic_info_data.get("location"),
            experience_years=basic_info_data.get("experience_years", 0),
            current_role=basic_info_data.get("current_role"),
            current_company=basic_info_data.get("current_company")
        )
        
        # æ•™è‚²èƒŒæ™¯
        education_list = []
        for edu_data in structured_data.get("education", []):
            education = Education(
                degree=edu_data.get("degree"),
                major=edu_data.get("major"),
                school=edu_data.get("school"),
                graduation_year=edu_data.get("graduation_year"),
                gpa=edu_data.get("gpa")
            )
            education_list.append(education)
        
        # å·¥ä½œç»å†
        work_experience_list = []
        for work_data in structured_data.get("work_experience", []):
            work_exp = WorkExperience(
                company=work_data.get("company"),
                position=work_data.get("position"),
                start_date=work_data.get("start_date"),
                end_date=work_data.get("end_date"),
                description=work_data.get("description"),
                achievements=work_data.get("achievements", [])
            )
            work_experience_list.append(work_exp)
        
        # æŠ€èƒ½ä¿¡æ¯
        skills_list = []
        for skill_data in structured_data.get("skills", []):
            skill = Skill(
                name=skill_data.get("name"),
                level=skill_data.get("level"),
                years_experience=skill_data.get("years_experience"),
                description=skill_data.get("description")
            )
            skills_list.append(skill)
        
        # å…¶ä»–ä¿¡æ¯
        certifications = structured_data.get("certifications", [])
        languages = structured_data.get("languages", [])
        projects = structured_data.get("projects", [])
        github_url = structured_data.get("github_url")
        linkedin_url = structured_data.get("linkedin_url")
        
        return CandidateProfile(
            id=f"candidate_{len(work_experience_list)}_{len(skills_list)}",  # ç®€å•IDç”Ÿæˆ
            basic_info=basic_info,
            education=education_list,
            work_experience=work_experience_list,
            skills=skills_list,
            certifications=certifications,
            languages=languages,
            projects=projects,
            github_url=github_url,
            linkedin_url=linkedin_url
        )

    async def _parse_resumes_with_progress(self, resume_files: List[str], progress_callback: Optional[Callable] = None) -> List[Dict[str, Any]]:
        """è§£æç®€å†æ–‡ä»¶ï¼ˆå¸¦è¿›åº¦ï¼‰"""
        parsed_resumes = []
        
        for i, file_path in enumerate(resume_files):
            if progress_callback:
                await progress_callback({
                    "stage": "resume_processing",
                    "message": f"Parsing resume file: {os.path.basename(file_path)}",
                    "progress": 15 + (i / len(resume_files)) * 10,
                    "current_item": os.path.basename(file_path),
                    "total_items": len(resume_files),
                    "completed_items": i
                })
            
            try:
                parsed_resume = await self._parse_single_resume(file_path)
                parsed_resumes.append(parsed_resume)
            except Exception as e:
                print(f"âŒ è§£æç®€å†å¤±è´¥ {file_path}: {str(e)}")
                parsed_resumes.append({
                    "status": "error",
                    "error": str(e),
                    "file_path": file_path
                })
        
        return parsed_resumes

    async def _parse_single_resume(self, file_path: str) -> Dict[str, Any]:
        """è§£æå•ä¸ªç®€å†æ–‡ä»¶"""
        try:
            # è§£æç®€å†æ–‡ä»¶
            parse_result = await self.resume_parser.parse_resume_file(file_path)
            
            if parse_result["status"] == "error":
                raise ValueError(parse_result["error"])
            
            content = parse_result["content"]
            
            if not content or content.strip() == "":
                raise ValueError("æ–‡ä»¶å†…å®¹ä¸ºç©º")
            
            return {
                "status": "success",
                "file_path": file_path,
                "file_name": os.path.basename(file_path),
                "content": content
            }
        except Exception as e:
            print(f"âŒ è§£æå•ä¸ªç®€å†å¤±è´¥ {file_path}: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "file_path": file_path
            }

    async def _process_resumes_concurrently_stream(self, parsed_resumes: List[Dict[str, Any]], progress_callback: Optional[Callable] = None) -> List[Dict[str, Any]]:
        """å¹¶å‘å¤„ç†ç®€å†ç»“æ„åŒ–ï¼ˆå¸¦è¿›åº¦ï¼‰"""
        semaphore = asyncio.Semaphore(self.max_concurrent)
        completed_count = 0
        
        async def process_single_resume_stream(resume_data):
            nonlocal completed_count
            async with semaphore:
                result = await self._structure_single_resume(resume_data)
                completed_count += 1
                
                if progress_callback:
                    await progress_callback({
                        "stage": "resume_processing",
                        "message": f"Completed resume structuring: {os.path.basename(resume_data.get('file_path', 'unknown'))}",
                        "progress": 25 + (completed_count / len(parsed_resumes)) * 10,
                        "current_item": os.path.basename(resume_data.get('file_path', 'unknown')),
                        "total_items": len(parsed_resumes),
                        "completed_items": completed_count
                    })
                
                return result
        
        tasks = [process_single_resume_stream(resume) for resume in parsed_resumes]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸ç»“æœ
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                processed_results.append({
                    "status": "error",
                    "error": str(result),
                    "file_path": parsed_resumes[i]["file_path"]
                })
            else:
                processed_results.append(result)
        
        return processed_results
    
    async def run_standalone(self, resume_files: List[str]) -> List[CandidateProfile]:
        """ç‹¬ç«‹è¿è¡Œæ¨¡å¼"""
        result = await self.process(resume_files)
        
        if result["status"] == "success":
            print(f"ç®€å†ç»“æ„åŒ–å®Œæˆ: {result['successful_structured']}/{result['total_files']} ä¸ªæ–‡ä»¶")
            return result["candidate_profiles"]
        else:
            print(f"ç®€å†ç»“æ„åŒ–å¤±è´¥: {result['error']}")
            return []

async def main():
    """æµ‹è¯•å‡½æ•°"""
    # ç¤ºä¾‹ç®€å†æ–‡ä»¶è·¯å¾„
    resume_files = [
        "path/to/resume1.pdf",
        "path/to/resume2.docx"
    ]
    
    node = ResumeStructureNode()
    candidate_profiles = await node.run_standalone(resume_files)
    
    for profile in candidate_profiles:
        print(f"å€™é€‰äºº: {profile.basic_info.name}")
        print(f"èŒä½: {profile.basic_info.current_role}")
        print(f"å…¬å¸: {profile.basic_info.current_company}")
        print(f"ç»éªŒ: {profile.basic_info.experience_years}å¹´")
        print("---")

if __name__ == "__main__":
    asyncio.run(main())