import asyncio
import time
from typing import Dict, Any, List, Optional, Callable
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

from src.workflow import HRAgentWorkflow
from src.nodes import (
    RequirementConfirmationNode,
    ScoringDimensionNode,
    ResumeStructureNode,
    CandidateEvaluationNode,
    ReportGenerationNode
)
from src.models import RequirementConfirmationState
from datetime import datetime
import os

class OptimizedHRAgentWorkflow:
    """å¼‚æ­¥ä¼˜åŒ–HRæ™ºèƒ½ä½“å·¥ä½œæµ"""
    
    def __init__(self, max_concurrent_resumes: int = 10, max_concurrent_evaluations: int = 8):
        self.requirement_node = RequirementConfirmationNode()
        self.dimension_node = ScoringDimensionNode()
        self.resume_node = ResumeStructureNode(max_concurrent=max_concurrent_resumes)
        self.evaluation_node = CandidateEvaluationNode(max_concurrent=max_concurrent_evaluations)
        self.report_node = ReportGenerationNode()
        
    async def run_web_workflow(self, job_requirement, resume_files: List[str]) -> Dict[str, Any]:
        """è¿è¡ŒWebç‰ˆå·¥ä½œæµï¼ˆè·³è¿‡äº¤äº’å¼éœ€æ±‚ç¡®è®¤ï¼‰"""
        print("=== ğŸš€ HRæ™ºèƒ½ä½“ç®€å†ç­›é€‰ç³»ç»Ÿ (Webç‰ˆ) ===")
        print(f"èŒä½: {job_requirement.position}")
        print(f"ç®€å†æ–‡ä»¶æ•°é‡: {len(resume_files)} ä¸ª")
        
        # éªŒè¯ç®€å†æ–‡ä»¶
        existing_files = [f for f in resume_files if os.path.exists(f)]
        
        if not existing_files:
            raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„ç®€å†æ–‡ä»¶")
        
        start_time = time.time()
        print(f"â±ï¸ å¼€å§‹æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")
        
        try:
            # æ­¥éª¤1: ç®€å†å¤„ç†ï¼ˆè·³è¿‡éœ€æ±‚ç¡®è®¤ï¼‰
            print("\n=== ğŸ“‹ æ­¥éª¤1: ç®€å†å¤„ç† ===")
            candidate_profiles = await self._handle_resume_processing(existing_files)
            
            # æ­¥éª¤2: ç”Ÿæˆè¯„åˆ†ç»´åº¦
            print("\n=== ğŸ“Š æ­¥éª¤2: ç”Ÿæˆè¯„åˆ†ç»´åº¦ ===")
            step2_start = time.time()
            
            result = await asyncio.get_event_loop().run_in_executor(
                None, self.dimension_node.process, job_requirement
            )
            if result["status"] != "success":
                raise ValueError(f"è¯„åˆ†ç»´åº¦ç”Ÿæˆå¤±è´¥: {result['error']}")
            
            scoring_dimensions = result["scoring_dimensions"]
            print(f"âœ… è¯„åˆ†ç»´åº¦ç”ŸæˆæˆåŠŸï¼Œè€—æ—¶: {time.time() - step2_start:.1f}ç§’")
            
            # æ­¥éª¤3: å€™é€‰äººè¯„åˆ†
            print("\n=== ğŸ¯ æ­¥éª¤3: å€™é€‰äººè¯„åˆ† ===")
            step3_start = time.time()
            
            result = await self.evaluation_node.process(
                candidate_profiles, job_requirement, scoring_dimensions
            )
            if result["status"] != "success":
                raise ValueError(f"å€™é€‰äººè¯„åˆ†å¤±è´¥: {result['error']}")
            
            evaluations = result["evaluations"]
            print(f"âœ… å€™é€‰äººè¯„åˆ†å®Œæˆï¼Œè€—æ—¶: {time.time() - step3_start:.1f}ç§’")
            
            # æ­¥éª¤4: ç”ŸæˆæŠ¥å‘Š
            print("\n=== ğŸ“ˆ æ­¥éª¤4: ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š ===")
            step4_start = time.time()
            
            result = self.report_node.process(evaluations, job_requirement, scoring_dimensions)
            if result["status"] != "success":
                raise ValueError(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {result['error']}")
            
            # ä¿å­˜æŠ¥å‘Š
            report = result["report"]
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"candidate_evaluation_report_web_{timestamp}.md"
            saved_file = self.report_node.save_report(report, filename)
            
            total_duration = time.time() - start_time
            print(f"\nğŸ‰ Webå·¥ä½œæµå®Œæˆï¼æ€»è€—æ—¶: {total_duration:.1f}ç§’")
            
            return {
                "evaluations": evaluations,
                "final_report": report,
                "report_file": saved_file,
                "job_requirement": job_requirement,
                "scoring_dimensions": scoring_dimensions,
                "total_duration": total_duration
            }
            
        except Exception as e:
            print(f"\nâŒ Webå·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}")
            raise

    async def run_web_workflow_stream(self, job_requirement, resume_files: List[str], 
                                     progress_callback: Optional[Callable] = None) -> Dict[str, Any]:
        """è¿è¡ŒWebç‰ˆå·¥ä½œæµï¼ˆå¸¦è¿›åº¦æµå¼è¾“å‡ºï¼‰"""
        if progress_callback:
            await progress_callback({
                "stage": "initialization",
                "message": f"å¼€å§‹å¤„ç†èŒä½: {job_requirement.position}",
                "progress": 0,
                "total_items": len(resume_files),
                "completed_items": 0
            })
        
        # éªŒè¯ç®€å†æ–‡ä»¶
        existing_files = [f for f in resume_files if os.path.exists(f)]
        
        if not existing_files:
            raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„ç®€å†æ–‡ä»¶")
        
        start_time = time.time()
        
        try:
            # æ­¥éª¤1: ç®€å†å¤„ç†ï¼ˆå¸¦è¿›åº¦ï¼‰
            if progress_callback:
                await progress_callback({
                    "stage": "resume_processing",
                    "message": "å¼€å§‹å¤„ç†ç®€å†æ–‡ä»¶",
                    "progress": 10,
                    "total_items": len(existing_files),
                    "completed_items": 0
                })
            
            candidate_profiles = await self._handle_resume_processing_stream(existing_files, progress_callback)
            
            # æ­¥éª¤2: ç”Ÿæˆè¯„åˆ†ç»´åº¦
            if progress_callback:
                await progress_callback({
                    "stage": "dimension_generation",
                    "message": "ç”Ÿæˆè¯„åˆ†ç»´åº¦",
                    "progress": 40,
                    "total_items": 1,
                    "completed_items": 0
                })
            
            scoring_dimensions = await self._handle_dimension_generation_stream(job_requirement, progress_callback)
            
            # æ­¥éª¤3: å€™é€‰äººè¯„ä¼°
            if progress_callback:
                await progress_callback({
                    "stage": "candidate_evaluation",
                    "message": "å¼€å§‹å€™é€‰äººè¯„ä¼°",
                    "progress": 60,
                    "total_items": len(candidate_profiles),
                    "completed_items": 0
                })
            
            evaluation_result = await self._handle_candidate_evaluation_stream(
                candidate_profiles, job_requirement, scoring_dimensions, progress_callback
            )
            
            # æ­¥éª¤4: æŠ¥å‘Šç”Ÿæˆ
            if progress_callback:
                await progress_callback({
                    "stage": "report_generation",
                    "message": "ç”Ÿæˆå€™é€‰äººè¯„ä¼°æŠ¥å‘Š",
                    "progress": 90,
                    "total_items": 1,
                    "completed_items": 0
                })
            
            report_result = await self._handle_report_generation_stream(
                evaluation_result, job_requirement, scoring_dimensions, progress_callback
            )
            
            # å®Œæˆ
            if progress_callback:
                await progress_callback({
                    "stage": "complete",
                    "message": "å¤„ç†å®Œæˆ",
                    "progress": 100,
                    "total_items": len(resume_files),
                    "completed_items": len(resume_files)
                })
            
            return report_result
            
        except Exception as e:
            if progress_callback:
                await progress_callback({
                    "stage": "error",
                    "message": f"å¤„ç†å‡ºé”™: {str(e)}",
                    "progress": 0,
                    "error": str(e)
                })
            raise

    async def run_optimized_workflow(self, jd_text: str, resume_files: List[str]) -> Dict[str, Any]:
        """è¿è¡Œç®€åŒ–ä¼˜åŒ–ç‰ˆå·¥ä½œæµ"""
        print("=== ğŸš€ HRæ™ºèƒ½ä½“ç®€å†ç­›é€‰ç³»ç»Ÿ (å¼‚æ­¥ä¼˜åŒ–ç‰ˆ) ===")
        print(f"JDæ–‡æœ¬é•¿åº¦: {len(jd_text)} å­—ç¬¦")
        print(f"ç®€å†æ–‡ä»¶æ•°é‡: {len(resume_files)} ä¸ª")
        print("âœ¨ å¯ç”¨å¹¶è¡Œå¤„ç†ä¼˜åŒ–")
        
        # éªŒè¯ç®€å†æ–‡ä»¶
        existing_files = [f for f in resume_files if os.path.exists(f)]
        
        if not existing_files:
            raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„ç®€å†æ–‡ä»¶")
        
        start_time = time.time()
        print(f"â±ï¸ å¼€å§‹æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")
        
        try:
            # æ­¥éª¤1: å¹¶è¡Œæ‰§è¡Œéœ€æ±‚ç¡®è®¤å’Œç®€å†å¤„ç†
            print("\n=== ğŸš€ æ­¥éª¤1: å¯åŠ¨å¹¶è¡Œå¤„ç† ===")
            print("åŒæ—¶è¿›è¡Œéœ€æ±‚ç¡®è®¤å’Œç®€å†è§£æ...")
            
            # åˆ›å»ºå¹¶è¡Œä»»åŠ¡
            requirement_task = self._handle_requirement_confirmation(jd_text)
            resume_task = self._handle_resume_processing(existing_files)
            
            # å¹¶è¡Œæ‰§è¡Œ
            requirement_result, resume_result = await asyncio.gather(
                requirement_task, resume_task, return_exceptions=True
            )
            
            # å¤„ç†å¹¶è¡Œç»“æœ
            if isinstance(requirement_result, Exception):
                raise requirement_result
            if isinstance(resume_result, Exception):
                raise resume_result
            
            job_requirement = requirement_result
            candidate_profiles = resume_result
            
            parallel_duration = time.time() - start_time
            print(f"âœ… å¹¶è¡Œå¤„ç†å®Œæˆï¼Œè€—æ—¶: {parallel_duration:.1f}ç§’")
            
            # æ­¥éª¤2: ç”Ÿæˆè¯„åˆ†ç»´åº¦ (å¼‚æ­¥ä¼˜åŒ–)
            print("\n=== ğŸ“Š æ­¥éª¤2: ç”Ÿæˆè¯„åˆ†ç»´åº¦ (å¼‚æ­¥ä¼˜åŒ–) ===")
            step2_start = time.time()
            
            # å¼‚æ­¥è°ƒç”¨è¯„åˆ†ç»´åº¦ç”Ÿæˆ
            result = await asyncio.get_event_loop().run_in_executor(
                None, self.dimension_node.process, job_requirement
            )
            if result["status"] != "success":
                raise ValueError(f"è¯„åˆ†ç»´åº¦ç”Ÿæˆå¤±è´¥: {result['error']}")
            
            scoring_dimensions = result["scoring_dimensions"]
            print(f"âœ… è¯„åˆ†ç»´åº¦ç”ŸæˆæˆåŠŸï¼Œè€—æ—¶: {time.time() - step2_start:.1f}ç§’")
            print(f"ç”Ÿæˆäº† {len(scoring_dimensions.dimensions)} ä¸ªè¯„åˆ†ç»´åº¦")
            
            # æ­¥éª¤3: å€™é€‰äººè¯„åˆ† (è¶…çº§å¹¶å‘ä¼˜åŒ–)
            print("\n=== ğŸ¯ æ­¥éª¤3: å€™é€‰äººè¯„åˆ† (è¶…çº§å¹¶å‘ä¼˜åŒ–) ===")
            step3_start = time.time()
            
            # åŠ¨æ€è°ƒæ•´å¹¶å‘æ•°ä»¥æå‡æ€§èƒ½
            enhanced_evaluation_node = CandidateEvaluationNode(
                max_concurrent=min(12, len(candidate_profiles) * 2)
            )
            result = await enhanced_evaluation_node.process(
                candidate_profiles, job_requirement, scoring_dimensions
            )
            if result["status"] != "success":
                raise ValueError(f"å€™é€‰äººè¯„åˆ†å¤±è´¥: {result['error']}")
            
            evaluations = result["evaluations"]
            print(f"âœ… å€™é€‰äººè¯„åˆ†å®Œæˆï¼Œè€—æ—¶: {time.time() - step3_start:.1f}ç§’")
            print(f"æˆåŠŸè¯„åˆ† {len(evaluations)} ä¸ªå€™é€‰äºº")
            
            # æ˜¾ç¤ºæ’å
            print("\nå€™é€‰äººæ’å:")
            for eval in evaluations[:5]:
                print(f"{eval.ranking}. {eval.candidate_name} - {eval.overall_score:.1f}/10")
            
            # æ­¥éª¤4: ç”ŸæˆæŠ¥å‘Š
            print("\n=== ğŸ“ˆ æ­¥éª¤4: ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š ===")
            step4_start = time.time()
            
            result = self.report_node.process(evaluations, job_requirement, scoring_dimensions)
            if result["status"] != "success":
                raise ValueError(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {result['error']}")
            
            # ä¿å­˜æŠ¥å‘Š
            report = result["report"]
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"candidate_evaluation_report_optimized_{timestamp}.md"
            saved_file = self.report_node.save_report(report, filename)
            
            print(f"âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {time.time() - step4_start:.1f}ç§’")
            if saved_file:
                print(f"æŠ¥å‘Šå·²ä¿å­˜è‡³: {saved_file}")
            
            # æ€»ç»“
            total_duration = time.time() - start_time
            print(f"\n=== âœ… å¼‚æ­¥ä¼˜åŒ–å·¥ä½œæµæ‰§è¡Œå®Œæˆ ===")
            print(f"â±ï¸ æ€»è€—æ—¶: {total_duration:.1f} ç§’")
            print(f"ğŸ“Š å€™é€‰äººæ•°é‡: {len(evaluations)}")
            print(f"ğŸ“„ æŠ¥å‘Šæ–‡ä»¶: {saved_file}")
            
            return {
                "evaluations": evaluations,
                "final_report": report,
                "report_file": saved_file,
                "total_duration": total_duration,
                "parallel_duration": parallel_duration
            }
            
        except Exception as e:
            print(f"\nâŒ å¼‚æ­¥ä¼˜åŒ–å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}")
            raise
    
    async def _handle_requirement_confirmation(self, jd_text: str):
        """å¤„ç†éœ€æ±‚ç¡®è®¤ï¼ˆå¹¶è¡Œä»»åŠ¡1ï¼‰"""
        print("ğŸ“‹ å¯åŠ¨éœ€æ±‚ç¡®è®¤...")
        
        requirement_state = RequirementConfirmationState(jd_text=jd_text)
        
        try:
            # å°è¯•äº¤äº’å¼ç¡®è®¤ï¼ˆå¸¦è¶…æ—¶ï¼‰
            result = await asyncio.wait_for(
                self._interactive_requirement_confirmation(requirement_state),
                timeout=30  # 30ç§’è¶…æ—¶
            )
            
            if result:
                print("âœ… éœ€æ±‚ç¡®è®¤å®Œæˆ (äº¤äº’æ¨¡å¼)")
                return requirement_state.to_job_requirement()
                
        except asyncio.TimeoutError:
            print("â° äº¤äº’è¶…æ—¶ï¼Œä½¿ç”¨è‡ªåŠ¨æå–")
        except (EOFError, KeyboardInterrupt):
            print("âš ï¸ äº¤äº’ä¸­æ–­ï¼Œä½¿ç”¨è‡ªåŠ¨æå–")
        
        # è‡ªåŠ¨æå–éœ€æ±‚
        self._auto_extract_requirements(requirement_state)
        print("âœ… éœ€æ±‚ç¡®è®¤å®Œæˆ (è‡ªåŠ¨æ¨¡å¼)")
        return requirement_state.to_job_requirement()
    
    async def _interactive_requirement_confirmation(self, requirement_state):
        """äº¤äº’å¼éœ€æ±‚ç¡®è®¤"""
        # ç”Ÿæˆåˆå§‹é—®é¢˜
        result = self.requirement_node.process(requirement_state)
        print(f"AIåŠ©æ‰‹: {result['message']}")
        
        max_attempts = 5
        attempt = 0
        
        while not requirement_state.is_complete and attempt < max_attempts:
            try:
                # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œinputï¼Œé¿å…é˜»å¡
                loop = asyncio.get_event_loop()
                user_input = await loop.run_in_executor(None, input, "\nHR: ")
                
                if user_input.lower() in ['quit', 'exit', 'é€€å‡º', '']:
                    break
                    
                result = self.requirement_node.process(requirement_state, user_input)
                print(f"AIåŠ©æ‰‹: {result['message']}")
                
                if result.get('is_complete'):
                    return True
                    
                attempt += 1
                
            except (EOFError, KeyboardInterrupt):
                break
        
        return False
    
    def _auto_extract_requirements(self, requirement_state):
        """è‡ªåŠ¨æå–éœ€æ±‚"""
        jd_text = requirement_state.jd_text.lower()
        
        # åŸºäºå…³é”®è¯è‡ªåŠ¨æå–éœ€æ±‚
        must_have = []
        nice_to_have = []
        deal_breaker = []
        
        # æå–å¿…è¦æ¡ä»¶
        if "5å¹´" in jd_text or "5+" in jd_text:
            must_have.append("5å¹´ä»¥ä¸Šå·¥ä½œç»éªŒ")
        if "java" in jd_text:
            must_have.append("Javaå¼€å‘ç»éªŒ")
        if "spring" in jd_text:
            must_have.append("Springæ¡†æ¶ç»éªŒ")
        if "mysql" in jd_text:
            must_have.append("MySQLæ•°æ®åº“ç»éªŒ")
        if "åˆ†å¸ƒå¼" in jd_text:
            must_have.append("åˆ†å¸ƒå¼ç³»ç»Ÿç»éªŒ")
        if "å¾®æœåŠ¡" in jd_text:
            must_have.append("å¾®æœåŠ¡æ¶æ„ç»éªŒ")
        
        # æå–åŠ åˆ†æ¡ä»¶
        if "å¤§å‚" in jd_text or "bat" in jd_text or "å­—èŠ‚" in jd_text:
            nice_to_have.append("å¤§å‚å·¥ä½œèƒŒæ™¯")
        if "å¼€æº" in jd_text:
            nice_to_have.append("å¼€æºé¡¹ç›®è´¡çŒ®")
        if "å›¢é˜Ÿ" in jd_text and "ç®¡ç†" in jd_text:
            nice_to_have.append("å›¢é˜Ÿç®¡ç†ç»éªŒ")
        if "kubernetes" in jd_text or "k8s" in jd_text:
            nice_to_have.append("Kubernetesç»éªŒ")
        
        # æå–æ’é™¤æ¡ä»¶  
        if "å°‘äº" in jd_text or "ä¸è¶³" in jd_text:
            deal_breaker.append("å·¥ä½œç»éªŒä¸è¶³")
        if "æ— æ³•" in jd_text and "æ²Ÿé€š" in jd_text:
            deal_breaker.append("æ²Ÿé€šèƒ½åŠ›å·®")
            
        # è®¾ç½®é»˜è®¤å€¼
        if not must_have:
            must_have = ["ç›¸å…³å·¥ä½œç»éªŒ", "æŠ€æœ¯åŸºç¡€æ‰å®"]
        if not nice_to_have:
            nice_to_have = ["å­¦ä¹ èƒ½åŠ›å¼º", "å›¢é˜Ÿåˆä½œç²¾ç¥"]
        if not deal_breaker:
            deal_breaker = ["ç»éªŒä¸¥é‡ä¸è¶³"]
        
        # æ›´æ–°çŠ¶æ€
        requirement_state.must_have = must_have
        requirement_state.nice_to_have = nice_to_have
        requirement_state.deal_breaker = deal_breaker
        requirement_state.is_complete = True
        
        print(f"âœ… è‡ªåŠ¨æå–éœ€æ±‚:")
        print(f"å¿…è¦æ¡ä»¶: {must_have}")
        print(f"åŠ åˆ†æ¡ä»¶: {nice_to_have}")
        print(f"æ’é™¤æ¡ä»¶: {deal_breaker}")
    
    async def _handle_resume_processing(self, resume_files: List[str]):
        """å¤„ç†ç®€å†è§£æï¼ˆå¹¶è¡Œä»»åŠ¡2ï¼‰"""
        print("ğŸ“„ å¯åŠ¨ç®€å†è§£æ...")
        
        # å¼‚æ­¥å¤„ç†ç®€å†
        result = await self.resume_node.process(resume_files)
        
        if result["status"] == "success":
            candidate_profiles = result["candidate_profiles"]
            print(f"âœ… ç®€å†å¤„ç†å®Œæˆï¼Œå¤„ç†äº† {len(candidate_profiles)} ä¸ªå€™é€‰äºº")
            return candidate_profiles
        else:
            raise ValueError(f"ç®€å†å¤„ç†å¤±è´¥: {result['error']}")

    async def _handle_resume_processing_stream(self, resume_files: List[str], progress_callback: Optional[Callable] = None):
        """å¤„ç†ç®€å†æ–‡ä»¶ï¼ˆå¸¦è¿›åº¦ï¼‰"""
        result = await self.resume_node.process_stream(resume_files, progress_callback)
        
        if result["status"] == "success":
            return result["candidate_profiles"]
        else:
            raise ValueError(f"ç®€å†å¤„ç†å¤±è´¥: {result['error']}")

    async def _handle_dimension_generation_stream(self, job_requirement, progress_callback: Optional[Callable] = None):
        """ç”Ÿæˆè¯„åˆ†ç»´åº¦ï¼ˆå¸¦è¿›åº¦ï¼‰"""
        if progress_callback:
            await progress_callback({
                "stage": "dimension_generation",
                "message": "åˆ†æèŒä½è¦æ±‚ï¼Œç”Ÿæˆè¯„åˆ†ç»´åº¦",
                "progress": 45,
                "current_item": "è¯„åˆ†ç»´åº¦"
            })
        
        result = await asyncio.get_event_loop().run_in_executor(
            None, self.dimension_node.process, job_requirement
        )
        
        if result["status"] != "success":
            raise ValueError(f"è¯„åˆ†ç»´åº¦ç”Ÿæˆå¤±è´¥: {result['error']}")
        
        if progress_callback:
            await progress_callback({
                "stage": "dimension_generation",
                "message": "è¯„åˆ†ç»´åº¦ç”Ÿæˆå®Œæˆ",
                "progress": 50,
                "current_item": "è¯„åˆ†ç»´åº¦"
            })
        
        return result["scoring_dimensions"]

    async def _handle_candidate_evaluation_stream(self, candidate_profiles, job_requirement, scoring_dimensions, progress_callback: Optional[Callable] = None):
        """å€™é€‰äººè¯„ä¼°ï¼ˆå¸¦è¿›åº¦ï¼‰"""
        result = await self.evaluation_node.process_stream(candidate_profiles, job_requirement, scoring_dimensions, progress_callback)
        
        if result["status"] != "success":
            raise ValueError(f"å€™é€‰äººè¯„åˆ†å¤±è´¥: {result['error']}")
        
        return result["evaluations"]

    async def _handle_report_generation_stream(self, evaluation_result, job_requirement, scoring_dimensions, progress_callback: Optional[Callable] = None):
        """æŠ¥å‘Šç”Ÿæˆï¼ˆå¸¦è¿›åº¦ï¼‰"""
        result = await self.report_node.process_stream(evaluation_result, job_requirement, scoring_dimensions, progress_callback)
        
        if result["status"] != "success":
            raise ValueError(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {result['error']}")
        
        # ä¿å­˜æŠ¥å‘Š
        report = result["report"]
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"candidate_evaluation_report_web_{timestamp}.md"
        saved_file = self.report_node.save_report(report, filename)
        
        return {
            "evaluations": evaluation_result,
            "final_report": report,
            "report_file": saved_file,
            "job_requirement": job_requirement,
            "scoring_dimensions": scoring_dimensions,
            "candidate_count": len(evaluation_result),
            "generated_at": datetime.now().isoformat()
        }


# æ€§èƒ½å¯¹æ¯”å·¥å…·
class WorkflowPerformanceComparator:
    """å·¥ä½œæµæ€§èƒ½å¯¹æ¯”å·¥å…·"""
    
    @staticmethod
    async def compare_workflows(jd_text: str, resume_files: List[str]):
        """å¯¹æ¯”åŸå§‹å·¥ä½œæµå’Œä¼˜åŒ–å·¥ä½œæµçš„æ€§èƒ½"""
        print("ğŸ”¬ å¼€å§‹å·¥ä½œæµæ€§èƒ½å¯¹æ¯”æµ‹è¯•")
        print("=" * 60)
        
        # è¿‡æ»¤å­˜åœ¨çš„æ–‡ä»¶
        existing_files = [f for f in resume_files if os.path.exists(f)]
        if len(existing_files) < 2:
            print("âŒ éœ€è¦è‡³å°‘2ä¸ªç®€å†æ–‡ä»¶æ¥æµ‹è¯•")
            return
        
        print(f"ğŸ“‹ ä½¿ç”¨ {len(existing_files)} ä¸ªç®€å†æ–‡ä»¶è¿›è¡Œæµ‹è¯•")
        
        # æµ‹è¯•åŸå§‹å·¥ä½œæµ
        print(f"\n{'='*20} æµ‹è¯•åŸå§‹å·¥ä½œæµ {'='*20}")
        original_workflow = HRAgentWorkflow()
        original_start = time.time()
        
        try:
            # ä½¿ç”¨ç©ºè¾“å…¥æ¨¡æ‹Ÿéäº¤äº’æ¨¡å¼
            await run_with_empty_input(
                original_workflow.run_workflow, jd_text, existing_files[:3]
            )
            original_duration = time.time() - original_start
            print(f"âœ… åŸå§‹å·¥ä½œæµå®Œæˆï¼Œè€—æ—¶: {original_duration:.1f}ç§’")
        except Exception as e:
            print(f"âŒ åŸå§‹å·¥ä½œæµå¤±è´¥: {e}")
            original_duration = float('inf')
        
        # æµ‹è¯•ä¼˜åŒ–å·¥ä½œæµ
        print(f"\n{'='*20} æµ‹è¯•ä¼˜åŒ–å·¥ä½œæµ {'='*20}")
        optimized_workflow = OptimizedHRAgentWorkflow(
            max_concurrent_resumes=10,
            max_concurrent_evaluations=8
        )
        optimized_start = time.time()
        
        try:
            result = await run_with_empty_input(
                optimized_workflow.run_optimized_workflow, jd_text, existing_files[:3]
            )
            optimized_duration = time.time() - optimized_start
            print(f"âœ… ä¼˜åŒ–å·¥ä½œæµå®Œæˆï¼Œè€—æ—¶: {optimized_duration:.1f}ç§’")
            
            # æ˜¾ç¤ºè¯¦ç»†æ€§èƒ½æ•°æ®
            if result and "parallel_duration" in result:
                print(f"å…¶ä¸­å¹¶è¡Œå¤„ç†è€—æ—¶: {result['parallel_duration']:.1f}ç§’")
                
        except Exception as e:
            print(f"âŒ ä¼˜åŒ–å·¥ä½œæµå¤±è´¥: {e}")
            optimized_duration = float('inf')
        
        # æ€§èƒ½å¯¹æ¯”
        print(f"\n{'='*20} æ€§èƒ½å¯¹æ¯”ç»“æœ {'='*20}")
        print(f"ğŸ“Š åŸå§‹å·¥ä½œæµ: {original_duration:.1f}ç§’")
        print(f"ğŸš€ ä¼˜åŒ–å·¥ä½œæµ: {optimized_duration:.1f}ç§’")
        
        if original_duration != float('inf') and optimized_duration != float('inf'):
            improvement = ((original_duration - optimized_duration) / original_duration) * 100
            time_saved = original_duration - optimized_duration
            
            print(f"âš¡ æ€§èƒ½æå‡: {improvement:.1f}%")
            print(f"ğŸ•’ èŠ‚çœæ—¶é—´: {time_saved:.1f}ç§’")
            
            if improvement > 0:
                print(f"ğŸ‰ ä¼˜åŒ–æˆåŠŸï¼")
            else:
                print(f"ğŸ¤” ä¼˜åŒ–æ•ˆæœä¸æ˜æ˜¾")
        else:
            print("âŒ æ— æ³•è¿›è¡Œæ€§èƒ½å¯¹æ¯”")
        
        return {
            "original_duration": original_duration,
            "optimized_duration": optimized_duration,
            "improvement_percentage": improvement if 'improvement' in locals() else 0
        }


async def run_with_empty_input(func, *args):
    """ä½¿ç”¨ç©ºè¾“å…¥è¿è¡Œå‡½æ•°ï¼Œæ¨¡æ‹Ÿéäº¤äº’æ¨¡å¼"""
    import sys
    from io import StringIO
    
    # ä¿å­˜åŸå§‹stdin
    original_stdin = sys.stdin
    
    try:
        # ä½¿ç”¨ç©ºè¾“å…¥
        sys.stdin = StringIO("\n" * 10)
        result = await func(*args)
        return result
    finally:
        # æ¢å¤åŸå§‹stdin
        sys.stdin = original_stdin


# ä½¿ç”¨ç¤ºä¾‹
async def main():
    """ç®€åŒ–ä¼˜åŒ–å·¥ä½œæµä½¿ç”¨ç¤ºä¾‹"""
    jd_text = """
é«˜çº§åç«¯å¼€å‘å·¥ç¨‹å¸ˆ

å²—ä½èŒè´£ï¼š
- è´Ÿè´£æ ¸å¿ƒäº¤æ˜“ç³»ç»Ÿçš„æ¶æ„è®¾è®¡å’Œå¼€å‘
- è®¾è®¡é«˜å¹¶å‘ã€é«˜å¯ç”¨çš„å¾®æœåŠ¡ç³»ç»Ÿ
- ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½ï¼Œå¤„ç†å¤§è§„æ¨¡æ•°æ®

ä»»èŒè¦æ±‚ï¼š
- 5å¹´ä»¥ä¸Šåç«¯å¼€å‘ç»éªŒ
- ç†Ÿç»ƒæŒæ¡Javaã€Spring Bootç­‰æŠ€æœ¯
- æœ‰åˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡ç»éªŒ
- äº†è§£Dockerã€Kubernetes
"""
    
    resume_files = [
        "examples/resume_candidate_a.txt",
        "examples/resume_candidate_b.txt", 
        "examples/resume_candidate_c.txt"
    ]
    
    # è¿è¡Œä¼˜åŒ–å·¥ä½œæµ
    optimized_workflow = OptimizedHRAgentWorkflow(
        max_concurrent_resumes=10,
        max_concurrent_evaluations=8
    )
    
    try:
        result = await optimized_workflow.run_optimized_workflow(jd_text, resume_files)
        print(f"\nğŸ‰ å¼‚æ­¥ä¼˜åŒ–å·¥ä½œæµæ‰§è¡ŒæˆåŠŸ!")
        
        # å¯é€‰ï¼šæ€§èƒ½å¯¹æ¯”
        print(f"\n{'='*60}")
        await WorkflowPerformanceComparator.compare_workflows(jd_text, resume_files)
        
    except Exception as e:
        print(f"âŒ å¼‚æ­¥ä¼˜åŒ–å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}")

if __name__ == "__main__":
    asyncio.run(main())